head()
flights %>%
group_by(carrier) %>%
select(month, day, dep_delay) %>%
filter(min_rank(desc(dep_delay)) <= 2 & dep_delay!="NA") %>%
arrange(carrier, desc(dep_delay)) %>%
head()
flights_latlon <- flights %>%
inner_join(select(airports, origin = faa, origin_lat = lat, origin_lon = lon), by = "origin") %>%
inner_join(select(airports, dest = faa, dest_lat = lat, dest_lon = lon), by = "dest")
flights_latlon %>%
filter(origin == "JFK") %>%
ggplot(aes(x = origin_lon, xend= dest_lon,
y = origin_lat, yend= dest_lat)) +
borders("state") +
geom_segment(arrow = arrow(length = unit(0.1, "cm")), color = "orange") +
coord_quickmap() +
labs(y = "Latitude", x= "Longitude")
View(flights_latlon)
flights_latlon %>%
filter(origin == "LGA") %>%
ggplot(aes(x = origin_lon, xend= dest_lon,
y = origin_lat, yend= dest_lat)) +
borders("state") +
geom_segment(arrow = arrow(length = unit(0.1, "cm")), color = "orange") +
coord_quickmap() +
labs(y = "Latitude", x= "Longitude")
flights_latlon %>%
filter(origin == "LGA") %>%
ggplot(aes(x = origin_lon, xend= dest_lon,
y = origin_lat, yend= dest_lat)) +
borders("state") +
geom_segment(arrow = arrow(length = unit(0.1, "cm")), color = "BLUE") +
coord_quickmap() +
labs(y = "Latitude", x= "Longitude")
flights_latlon %>%
group_by(dest) %>%
count()
flights_latlon %>%
group_by(dest) %>%
count(dest, sort=TRUE)
flights_latlon %>%
group_by(dest) %>%
count(dest, sort=TRUE) %>%
tail(10)
flights_latlon %>%
filter(dest %in% c("HDN","MTJ","SBN","ANC","LEX","LGA")) %>%
ggplot(aes(
x = origin_lon, xend = dest_lon,
y = origin_lat, yend = dest_lat
)) +
borders("state") +
geom_segment(arrow = arrow(length = unit(0.1, "cm")), color = "pink") +
coord_quickmap() +
labs(y = "Latitude", x = "Longitude")
flights_latlon %>%
filter(dest %in% c("HDN","MTJ","SBN","ANC","LEX","LGA")) %>%
ggplot(aes(
x = origin_lon, xend = dest_lon,
y = origin_lat, yend = dest_lat
)) +
borders("state") +
geom_segment(arrow = arrow(length = unit(0.1, "cm")), color = "purple") +
coord_quickmap() +
labs(y = "Latitude", x = "Longitude")
flights_latlon %>%
filter(dest %in% c("HDN","MTJ","SBN","ANC","LEX","LGA")) %>%
ggplot(aes(
x = origin_lon, xend = dest_lon,
y = origin_lat, yend = dest_lat
)) +
borders("state") +
geom_segment(arrow = arrow(length = unit(0.5, "cm")), color = "purple") +
coord_quickmap() +
labs(y = "Latitude", x = "Longitude")
flights_latlon %>%
slice(1:100) %>%
ggplot(aes(
x = origin_lon, xend = dest_lon,
y = origin_lat, yend = dest_lat
)) +
borders("state") +
geom_segment(arrow = arrow(length = unit(0.1, "cm")), color = "orange") +
coord_quickmap() +
labs(y = "Latitude", x = "Longitude")
flights_latlon %>%
slice(101:150) %>%
ggplot(aes(
x = origin_lon, xend = dest_lon,
y = origin_lat, yend = dest_lat
)) +
borders("state") +
geom_segment(arrow = arrow(length = unit(0.1, "cm")), color = "orange") +
coord_quickmap() +
labs(y = "Latitude", x = "Longitude")
flights_latlon %>%
slice(100:300) %>%
ggplot(aes(
x = origin_lon, xend = dest_lon,
y = origin_lat, yend = dest_lat
)) +
borders("state") +
geom_segment(arrow = arrow(length = unit(0.1, "cm")), color = "orange") +
coord_quickmap() +
labs(y = "Latitude", x = "Longitude")
library(echarts4r)
install.packages("echarts4r")
library(echarts4r)
top_destinations <- flights %>%
count(dest) %>%
top_n(15, n) %>%
arrange(n)
top_destinations <- flights %>%
count(dest) %>%
top_n(15, n) %>%
arrange(n)
top_destinations %>%
e_charts(x = dest) %>%
e_bar(n, legend = FALSE, name = "Flights") %>%
e_labels(position = "right") %>%
e_tooltip() %>%
e_title("Flights by destination", "Top 15 destinations") %>%
e_flip_coords() %>%
e_y_axis(splitLine = list(show = FALSE)) %>%
e_x_axis(show = FALSE) %>%
e_toolbox_feature(
feature = "saveAsImage",
title = "Save as image"
)
flights_daytime <- flights %>%
transmute(origin, daytime = case_when(
hour >= 22 & hour < 6 ~ "Night",
hour >= 6 & hour < 12 ~ "Morning",
hour >= 12 & hour < 18 ~ "Afternoon",
TRUE ~ "Evening"
)) %>%
count(origin, daytime) %>%
group_by(daytime)
flights_daytime
flights_daytime %>%
e_charts(origin, stack = "grp") %>%
e_bar(n) %>%
e_tooltip(
trigger = "axis",
axisPointer = list(
type = "shadow"
)
) %>%
e_title(
text = "Outgoing flights by time of day",
subtext = "There are no night flights"
) %>%
e_y_axis(
splitArea = list(show = FALSE),
splitLine = list(show = FALSE)
)
set.seed(123)
flights_sm <- flights %>%
filter(complete.cases(.)) %>%
sample_n(1000)
flights_sm %>%
e_charts(x = dep_delay) %>%
e_scatter(arr_delay, name = "Flight") %>%
e_lm(arr_delay ~ dep_delay, name = "Linear model") %>%
e_axis_labels(x = "Departure delay", y = "Arrival delay") %>%
e_title(
text = "Arrival delay vs. departure delay",
subtext = "The later you start, the later you finish"
) %>%
e_x_axis(
nameLocation = "center",
splitArea = list(show = FALSE),
axisLabel = list(margin = 3),
axisPointer = list(
show = TRUE,
lineStyle = list(
color = "#999999",
width = 0.75,
type = "dotted"
)
)
) %>%
e_y_axis(
nameLocation = "center",
splitArea = list(show = FALSE),
axisLabel = list(margin = 0),
axisPointer = list(
show = TRUE,
lineStyle = list(
color = "#999999",
width = 0.75,
type = "dotted"
)
)
)
n_bins <- 100
flights %>%
filter(complete.cases(.)) %>%
mutate(
arr_delay = cut(arr_delay, n_bins),
dep_delay = cut(dep_delay, n_bins)
) %>%
count(arr_delay, dep_delay) %>%
e_charts(dep_delay) %>%
e_heatmap(arr_delay, n) %>%
e_visual_map(n) %>%
e_title("Arrival delay vs. departure delay") %>%
e_axis_labels("Departure delay", "Arrival delay")
pie <- count(flights, origin) %>%
e_charts(x = origin) %>%
e_pie(n, legend = FALSE, name = "Flights") %>%
e_tooltip() %>%
e_title("Flights by origin", "This is really hard with ggplot2")
pie
flights_ts <- flights %>%
transmute(week = as.Date(cut(time_hour, "week")), dep_delay, origin) %>%
group_by(origin, week) %>% # works with echarts
summarise(dep_delay = sum(dep_delay, na.rm = TRUE))
View(flights_ts)
ts_base <- flights_ts %>%
e_charts(x = week) %>%
e_datazoom(
type = "slider",
toolbox = FALSE,
bottom = -5
) %>%
e_tooltip() %>%
e_title("Departure delays by airport") %>%
e_x_axis(week, axisPointer = list(show = TRUE))
ts_base %>% e_line(dep_delay)
area <- ts_base %>% e_area(dep_delay, stack = "grp")
area
install.packages("lubridate")
library(lubridate)
flights_ts %>%
filter(origin == "JFK") %>%
group_by(month = month(week, label = TRUE)) %>%
e_charts(x = week, timeline = TRUE) %>%
e_bar(
dep_delay,
name = "Departure Delay",
symbol = "none",
legend = FALSE
)
flights %>%
select(dep_time, sched_dep_time, dep_delay, arr_time, sched_arr_time, arr_delay, air_time, distance,hour) %>%
na.omit() %>%
cor() %>%
e_charts() %>%
e_correlations(order = "hclust") %>%
e_tooltip()
df <- data.frame(
x = c(
rnorm(100),
runif(100, -5, 10),
rnorm(100, 10, 3)
),
grp = c(
rep(LETTERS[1], 100),
rep(LETTERS[2], 100),
rep(LETTERS[3], 100)
)
)
df %>%
group_by(grp) %>%
e_charts() %>%
e_boxplot(x)
view(flights)
head(flights)
flights %>%
group_by(origin) %>%
count(n, sort = TRUE)
flights %>%
group_by(origin) %>%
count(origin, sort = TRUE)
flights
flights %>%
group_by(origin) %>%
e_charts() %>%
e_boxplot(distance)
?e_boxplot
flights %>%
group_by(origin) %>%
e_charts() %>%
e_boxplot(distance)
flights %>%
group_by(origin) %>%
e_charts(origin) %>%
e_boxplot(distance)
flights %>%
group_by(origin) %>%
e_charts(distance) %>%
e_boxplot(distance)
View(df)
flights %>%
group_by(origin) %>%
e_charts() %>%
e_boxplot(distance, name = origin)
flights
flights %>%
group_by(origin) %>%
e_charts(origin) %>%
e_boxplot(distance)
flights %>%
group_by(origin) %>%
e_charts() %>%
e_boxplot(distance)
library(h2o)
library(xgboost)
install.packages("xgboost")
install.packages("gbm")
install.packages("AER")
library(xgboost)
library(gbm)
library(AER)
library(rsample)
library(Metrics)
install.packages("Metrics")
library(Metrics)
data("CollegeDistance")
set.seed(123)
college_split <- initial_split(CollegeDistance, prop = .8)
college_train <- training(college_split)
college_test  <- testing(college_split)
set.seed(123)
college_gbm1 <- gbm(
formula = score ~ ., # score se modela mediante el resto de variables
data = college_train,
distribution = "gaussian",  # Función de pérdida cuadrática
n.trees = 1000, # Número de árboles
shrinkage = 0.1, # Learning rate
interaction.depth = 3, # Profundidad de los árboles
n.minobsinnode = 10, # Número mínimo de obs. x nodo
cv.folds = 10
)
print(ames_gbm1) ### características del modelo
college_gbm1 <- gbm(
formula = score ~ ., # score se modela mediante el resto de variables
data = college_train,
distribution = "gaussian",  # Función de pérdida cuadrática
n.trees = 1000, # Número de árboles
shrinkage = 0.1, # Learning rate
interaction.depth = 3, # Profundidad de los árboles
n.minobsinnode = 10, # Número mínimo de obs. x nodo
cv.folds = 10
)
print(ames_gbm1) ### características del modelo
print(college_gbm1) ### características del modelo
best <- which.min(college_gbm1$cv.error)
sqrt(college_gbm1$cv.error[best])
gbm.perf(college_gbm1, method = "cv")
perf_gbm1 = gbm.perf(college_gbm1, method = "cv")
summary(college_gbm1)
college_prediccion_1 <- stats::predict(
# El modelo
object = college_gbm1,
# Datos de validación
newdata = college_test,
# Número de árboles (calculado con la muestra de entrenamiento)
n.trees = perf_gbm1)
rmse_fit1 <- Metrics::rmse(actual = college_test$score,
predicted = college_prediccion_1)
print(rmse_fit1)
gbm::plot.gbm(college_gbm1, i.var = 2)
setwd("C:\Jairo.Ordonez\2. Personal\Especializacion_Analitica\Semestre_2\EspecializacionAnalitica\MLProbabilistico\bin")
setwd("C:/Jairo.Ordonez/2. Personal/Especializacion_Analitica/Semestre_2/EspecializacionAnalitica/MLProbabilistico/bin")
data = read.csv("../data/KPDRs_202011180830.csv", sep = "|")
head(data)
data$estado = ifelse(data$percentKPDR <= 85, 'OK', ifelse(data$percentKPDR > 85 & data$percentKPDR <=90, 'WARNING','ERROR'))
table(data$estado)
data$estado = ifelse(data$percentKPDR <= 85, 'OK', ifelse(data$percentKPDR > 85 & data$percentKPDR <=90, 'WARNING','ERROR'))
dataAntigua = data %>%
filter(data$date <= '2020-10-31')
library(dplyr)
data$estado = ifelse(data$percentKPDR <= 85, 'OK', ifelse(data$percentKPDR > 85 & data$percentKPDR <=90, 'WARNING','ERROR'))
dataAntigua = data %>%
filter(data$date <= '2020-10-31')
tail(dataAntigua)
library(rsample)
set.seed(20201116)
train_test_split <- rsample::initial_split(data = dataAntigua, prop = 0.80, strata = "estado")
train_data <- train_test_split %>% training()
test_data <- train_test_split %>% testing()
tail(dataAntigua)
data$estado = ifelse(data$percentKPDR <= 85, 'OK', ifelse(data$percentKPDR > 85 & data$percentKPDR <=90, 'WARNING','ERROR'))
dataAntigua = data %>%
filter(data$date <= '2020-10-31') %>%
select(-date, -percentKPDR)
tail(dataAntigua)
set.seed(20201116)
train_test_split <- rsample::initial_split(data = dataAntigua, prop = 0.80, strata = "estado")
train_data <- train_test_split %>% training()
test_data <- train_test_split %>% testing()
n_features <- length(setdiff(names(train_data), "estado"))
KPDR_RandomForest1 <- ranger(
estado ~ .,
data = train_data,
num.trees = 500,
mtry = floor(n_features / 3),
max.depth = 10,
respect.unordered.factors = "order",
seed = 20201116
)
library(ranger)
n_features <- length(setdiff(names(train_data), "estado"))
KPDR_RandomForest1 <- ranger(
estado ~ .,
data = train_data,
num.trees = 500,
mtry = floor(n_features / 3),
max.depth = 10,
respect.unordered.factors = "order",
seed = 20201116
)
data = read.csv("../data/KPDRs_202011180830.csv", sep = "|")
head(data)
dataAntigua = data %>%
filter(data$date <= '2020-10-31') %>%
select(-date)
tail(dataAntigua)
set.seed(20201116)
train_test_split <- rsample::initial_split(data = dataAntigua, prop = 0.80)
train_data <- train_test_split %>% training()
test_data <- train_test_split %>% testing()
n_features <- length(setdiff(names(train_data), "percentKPDR"))
KPDR_RandomForest1 <- ranger(
percentKPDR ~ .,
data = train_data,
num.trees = 500,
mtry = floor(n_features / 3),
max.depth = 10,
respect.unordered.factors = "order",
seed = 20201116
)
y_pred1 <- predict(KPDR_RandomForest1, data = test_data)$predictions
plot(test_data$percentKPDR , y_pred1 )
abline(a = 0, b = 1, col = "red")
# RMSE
sqrt(mean((test_data$percentKPDR - y_pred1)^2))
param_grid <- expand.grid(
mtry = floor(n_features * c(.05, .15, .25, .333, .4)),
min.node.size = c(1, 3, 5, 10),
replace = c(TRUE, FALSE),
sample.fraction = c(.5, .63, .8),
rmse = NA
)
param_grid <- expand.grid(
mtry = floor(n_features * c(.05, .15, .25, .333, .4)),
min.node.size = c(1, 3, 5, 10),
replace = c(TRUE, FALSE),
sample.fraction = c(.5, .63, .8),
rmse = NA
)
for(i in seq_len(nrow(param_grid))) {
fit <- ranger(
formula         = percentKPDR ~ .,
data            = train_data,
num.trees       = n_features * 10,
mtry            = param_grid$mtry[i],
min.node.size   = param_grid$min.node.size[i],
replace         = param_grid$replace[i],
sample.fraction = param_grid$sample.fraction[i],
verbose         = FALSE,
seed            = 20201116,
respect.unordered.factors = 'order',
)
param_grid$rmse[i] <- sqrt(fit$prediction.error)
}
# assess top 10 models
a <- param_grid %>%
arrange(rmse) %>%
head(10)
a
KPDR_RandomForestFinalModel <- ranger(
percentKPDR ~ .,
data = train_data,
num.trees = 500,
mtry = 4,
replace = F,
sample.fraction = 0.63,
min.node.size = 1
max.depth = NULL,
KPDR_RandomForestFinalModel <- ranger(
percentKPDR ~ .,
data = train_data,
num.trees = 500,
mtry = 4,
replace = F,
sample.fraction = 0.63,
min.node.size = 1,
max.depth = NULL,
seed = 20201116
)
y_predFinal <- predict(KPDR_RandomForestFinalModel, data = test_data)$predictions
plot(test_data$percentKPDR , y_predFinal)
abline(a = 0, b = 1, col = "red")
# RMSE
sqrt(mean((test_data$percentKPDR - y_predFinal)^2))
summary(KPDR_RandomForestFinalModel)
dataNueva = data %>%
filter(data$date > '2020-10-31') %>%
select(-date)
y_predNueva = predict(KPDR_RandomForestFinalModel, data = dataNueva)$predictions
plot(dataNueva$percentKPDR , y_predNueva)
abline(a = 0, b = 1, col = "red")
# RMSE
sqrt(mean((dataNueva$percentKPDR - y_predNueva)^2))
export.model(KPDR_RandomForestFinalModel, replace = TRUE)
install.packages("RMark")
library(RMark)
export.model(KPDR_RandomForestFinalModel, replace = TRUE)
saveRDS(KPDR_RandomForestFinalModel, "./modeloRandomForestInR.rds")
